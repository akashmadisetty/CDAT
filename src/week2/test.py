"""
Quick diagnostic to check ALL 4 domain pairs for data leakage
Run this to see which pairs need regeneration
"""

import pandas as pd
import numpy as np
from scipy.stats import ks_2samp

DOMAINS = {
    1: {'name': 'Cleaning & Household ‚Üí Foodgrains', 'transferability': 'HIGH (0.903)'},
    2: {'name': 'Snacks ‚Üí Fruits & Vegetables', 'transferability': 'MODERATE (0.548)'},
    3: {'name': 'Premium ‚Üí Budget', 'transferability': 'LOW (0.715)'},
    4: {'name': 'Popular ‚Üí Niche Brands', 'transferability': 'LOW-MOD (0.874)'}
}

print("="*80)
print("üîç CHECKING ALL DOMAIN PAIRS FOR DATA LEAKAGE")
print("="*80)

results = []
critical_issues = []

for pair_id, info in DOMAINS.items():
    print(f"\n{'='*80}")
    print(f"üì¶ DOMAIN PAIR {pair_id}: {info['name']}")
    print(f"   Week 1 Prediction: {info['transferability']}")
    print('='*80)
    
    try:
        # Load files
        source = pd.read_csv(f'domain_pair{pair_id}_source_RFM.csv')
        target = pd.read_csv(f'domain_pair{pair_id}_target_RFM.csv')
        
        print(f"\n‚úÖ Files loaded")
        print(f"   Source: {len(source)} customers")
        print(f"   Target: {len(target)} customers")
        
        # Check 1: Customer overlap
        source_ids = set(source['customer_id'])
        target_ids = set(target['customer_id'])
        overlap = source_ids & target_ids
        
        overlap_pct = (len(overlap) / len(source_ids)) * 100 if len(source_ids) > 0 else 0
        
        if len(overlap) > 0:
            print(f"\n‚ùå CRITICAL: {len(overlap)} customers overlap ({overlap_pct:.1f}% of source)")
            critical_issues.append(f"Pair {pair_id}: {len(overlap)} overlapping customers")
        else:
            print(f"\n‚úÖ No customer overlap")
        
        # Check 2: Missing values
        source_missing = source[['Recency', 'Frequency', 'Monetary']].isnull().sum().sum()
        target_missing = target[['Recency', 'Frequency', 'Monetary']].isnull().sum().sum()
        
        if source_missing > 0 or target_missing > 0:
            print(f"\n‚ö†Ô∏è  Missing values: Source={source_missing}, Target={target_missing}")
            critical_issues.append(f"Pair {pair_id}: Missing values detected")
        else:
            print(f"‚úÖ No missing values")
        
        # Check 3: Distribution similarity (KS test)
        ks_r = ks_2samp(source['Recency'], target['Recency'])
        ks_f = ks_2samp(source['Frequency'], target['Frequency'])
        ks_m = ks_2samp(source['Monetary'], target['Monetary'])
        
        avg_p_value = np.mean([ks_r.pvalue, ks_f.pvalue, ks_m.pvalue])
        
        print(f"\nüìä Distribution Similarity (KS Test):")
        print(f"   Recency:   p={ks_r.pvalue:.4f} {'‚ö†Ô∏è  TOO SIMILAR' if ks_r.pvalue > 0.05 else '‚úÖ Different'}")
        print(f"   Frequency: p={ks_f.pvalue:.4f} {'‚ö†Ô∏è  TOO SIMILAR' if ks_f.pvalue > 0.05 else '‚úÖ Different'}")
        print(f"   Monetary:  p={ks_m.pvalue:.4f} {'‚ö†Ô∏è  TOO SIMILAR' if ks_m.pvalue > 0.05 else '‚úÖ Different'}")
        
        # Check 4: MMD calculation
        from sklearn.preprocessing import StandardScaler
        
        X_source = source[['Recency', 'Frequency', 'Monetary']].values
        X_target = target[['Recency', 'Frequency', 'Monetary']].values
        
        scaler = StandardScaler()
        X_source_scaled = scaler.fit_transform(X_source)
        X_target_scaled = scaler.transform(X_target)
        
        # Simple MMD
        def compute_mmd(X, Y):
            XX = np.dot(X, X.T)
            YY = np.dot(Y, Y.T)
            XY = np.dot(X, Y.T)
            return np.mean(XX) + np.mean(YY) - 2 * np.mean(XY)
        
        mmd = compute_mmd(X_source_scaled, X_target_scaled)
        
        print(f"\nüìä MMD Score: {mmd:.4f}")
        if mmd < 0.1:
            print(f"   ‚ö†Ô∏è  EXTREMELY LOW - Source and target are too similar!")
            if len(overlap) > 0:
                print(f"   ‚Üí Likely caused by customer overlap")
        elif mmd < 0.3:
            print(f"   ‚úÖ LOW - Good transfer expected")
        elif mmd < 0.6:
            print(f"   ‚ö†Ô∏è  MODERATE - Transfer needs fine-tuning")
        else:
            print(f"   ‚ùå HIGH - Poor transfer expected")
        
        # Store results
        results.append({
            'pair': pair_id,
            'name': info['name'],
            'source_n': len(source),
            'target_n': len(target),
            'overlap': len(overlap),
            'overlap_pct': overlap_pct,
            'missing': source_missing + target_missing,
            'mmd': mmd,
            'avg_ks_pvalue': avg_p_value,
            'status': '‚ùå CRITICAL' if len(overlap) > 0 else ('‚ö†Ô∏è  WARNING' if avg_p_value > 0.1 else '‚úÖ OK')
        })
        
    except FileNotFoundError as e:
        print(f"\n‚ùå ERROR: File not found - {e}")
        results.append({
            'pair': pair_id,
            'name': info['name'],
            'status': '‚ùå FILE NOT FOUND'
        })
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        results.append({
            'pair': pair_id,
            'name': info['name'],
            'status': f'‚ùå ERROR: {str(e)}'
        })

# Summary report
print("\n" + "="*80)
print("üìä SUMMARY REPORT")
print("="*80)

df_results = pd.DataFrame(results)

# Display table
print("\n" + df_results.to_string(index=False))

# Count issues
pairs_with_overlap = sum(1 for r in results if r.get('overlap', 0) > 0)
pairs_ok = sum(1 for r in results if r.get('status', '') == '‚úÖ OK')

print("\n" + "="*80)
print("üéØ FINAL VERDICT")
print("="*80)

if len(critical_issues) > 0:
    print(f"\n‚ùå REGENERATION NEEDED FOR {pairs_with_overlap} PAIR(S)")
    print("\nüö® Critical Issues Found:")
    for issue in critical_issues:
        print(f"   ‚Ä¢ {issue}")
    
    print("\nüìã Action Items:")
    print("   1. Contact Member 1 (data generator)")
    print("   2. Share this diagnostic report")
    print("   3. Fix data generation to ensure DISJOINT customer sets")
    print("   4. Verify fix with: set(source['customer_id']) & set(target['customer_id']) == set()")
    print("   5. Re-generate ALL affected pairs")
    print("   6. Re-run training after data is fixed")
    
    print(f"\n‚è±Ô∏è  Estimated fix time: 2-3 hours")
    print(f"   ‚Ä¢ Member 1 fixes data: ~1-2 hours")
    print(f"   ‚Ä¢ You re-train models: ~10 minutes")
    
else:
    print(f"\n‚úÖ ALL PAIRS ARE VALID!")
    print(f"   ‚Ä¢ {pairs_ok} pairs have proper disjoint customer sets")
    print(f"   ‚Ä¢ No data leakage detected")
    print(f"   ‚Ä¢ Safe to continue with Week 2 deliverables")
    
    print("\nüí° Note on MMD scores:")
    for r in results:
        if 'mmd' in r:
            print(f"   ‚Ä¢ Pair {r['pair']}: MMD={r['mmd']:.3f} ‚Üí ", end="")
            if r['mmd'] < 0.3:
                print("Good transfer expected ‚úÖ")
            elif r['mmd'] < 0.6:
                print("Moderate transfer ‚ö†Ô∏è")
            else:
                print("Poor transfer (expected for this pair) ‚ùå")

print("\n" + "="*80)

# Save detailed report
df_results.to_csv('data_integrity_report.csv', index=False)
print("\n‚úÖ Detailed report saved: data_integrity_report.csv")
print("="*80)